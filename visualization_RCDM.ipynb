{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6731ea7",
   "metadata": {},
   "source": [
    "# Show recontructions (in-class variation)\n",
    "    - focus on showing highest confidence examples in single class for target model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3266aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import dejavu_utils.reconstruction_utils as ru\n",
    "import dejavu_utils.plot_utils as pu\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use(['science'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838a96c-4efb-425b-80b5-def5d42f460c",
   "metadata": {},
   "source": [
    "For this notebook to run, you will need to fill the following paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d223ed2e-844c-4989-9a25-2ac07373a039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging_folder = ''\n",
    "imgnet_dir = ''\n",
    "bbox_dir = ''\n",
    "bbox_idxs = ''\n",
    "model_A_pth = f'{logging_folder}/{model}/{model}_dssweep_{ds}pc_A/model_ep{epoch}.pth'\n",
    "model_B_pth = f'{logging_folder}/{model}/{model}_dssweep_{ds}pc_B/model_ep{epoch}.pth'\n",
    "rcdm_A_pth = f'{logging_folder}/RCDM/{model}/rcdm_{model}_{epoch}ep_{ds}pc_A/model600000.pt'\n",
    "rcdm_B_pth = f'{logging_folder}/{model}/rcdm_{model}_{epoch}ep_{ds}pc_B/model600000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66389d46-637f-4127-b194-89320360f3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'vicreg'\n",
    "attk_set = 'A'\n",
    "ref_set = 'B' if attk_set == 'A' else 'A'\n",
    "epoch = 1000\n",
    "ds = 300\n",
    "k_neighb = 100\n",
    "conf_gap_thresh = 3\n",
    "\n",
    "#ssl params \n",
    "mlp = '8192-8192-8192'\n",
    "gpu = 1\n",
    "\n",
    "with open(\"imgnet_classes.json\") as f:\n",
    "    imgnet_classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739afde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attk_data = ru.get_attack_data(model, ds, epoch, k_neighb)\n",
    "ru.print_class_statistics_sort_conf(attk_data, attk_set, epoch, ds, imgnet_classes, k = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a162bfd",
   "metadata": {},
   "source": [
    "### Load SSL and RCDM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d271e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.distributed.is_initialized(): \n",
    "    dist_url = Path(os.path.join('/scratch/', 'interactive_init'))\n",
    "    if dist_url.exists():\n",
    "        os.remove(str(dist_url))\n",
    "    dist_url = dist_url.as_uri()\n",
    "\n",
    "    torch.distributed.init_process_group(\n",
    "        backend='nccl', init_method=dist_url,\n",
    "        world_size=1, rank=0)                                    \n",
    "\n",
    "torch.cuda.set_device(gpu) \n",
    "\n",
    "ssl_model_A, ssl_model_B = ru.load_ssl_models(model_A_pth, model_B_pth, mlp, model)\n",
    "\n",
    "ssl_dim = ssl_model_A.module.representation_size + ssl_model_A.module.num_features\n",
    "RCDM_A, diff_A = ru.load_rcdm_model(rcdm_A_pth, ssl_dim)\n",
    "RCDM_B, diff_B = ru.load_rcdm_model(rcdm_B_pth, ssl_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d141c2f",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_idxs = attk_data[f'set_{attk_set}_idxs_{epoch}ep_{ds}pc']\n",
    "crop_ds = ru.aux_dataset(imgnet_dir, bbox_dir, attack_idxs, return_im_and_tgt = True) #dataset to load cropped images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3f09f",
   "metadata": {},
   "source": [
    "### Look at confident examples/patches in a given class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87622acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#badger\n",
    "cl = 362\n",
    "badger_patches, badger_idxs = ru.top_conf_show_class_examples(attk_data, attk_set, epoch, ds, \n",
    "                                                      cl, crop_ds, imgnet_classes, k = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd08161",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_badger_idx = [\n",
    "    42118,\n",
    "    126765,\n",
    "    55913,\n",
    "    16995\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c7dc6-70ea-4c66-ad8f-9227d69d8c86",
   "metadata": {},
   "source": [
    "#### Then use RCDM to sample images using the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506475d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_dict_badger = ru.gen_samples(\n",
    "        selected_badger_idx, \n",
    "        diff_A, diff_B,\n",
    "        ssl_model_A, ssl_model_B,\n",
    "        RCDM_A, RCDM_B,\n",
    "        epoch, ds,\n",
    "        attk_data,   \n",
    "        attk_set = 'A',\n",
    "        just_neighbs = False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
